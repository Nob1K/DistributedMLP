// This autogenerated skeleton file illustrates how to build a server.
// You should copy it to another filename to avoid overwriting it.

#include "gen-cpp/coordinator.h"
#include "ML.hpp"
#include "gen-cpp/Compute.h"
#include <iostream>
#include <fstream>
#include <sstream>
#include <string>
#include <vector>
#include <queue>
#include <mutex>
#include <thread>
#include <atomic>
#include <condition_variable>
#include <filesystem>
#include <thrift/protocol/TBinaryProtocol.h>
#include <thrift/server/TSimpleServer.h>
#include <thrift/transport/TServerSocket.h>
#include <thrift/transport/TBufferTransports.h>
#include <thrift/transport/TSocket.h>
#include <thrift/transport/TTransportUtils.h>

namespace fs = std::filesystem;
using namespace ::apache::thrift;
using namespace ::apache::thrift::protocol;
using namespace ::apache::thrift::transport;
using namespace ::apache::thrift::server;

// global for shared gradient and file_queue, mutex locks for them
weights shared_gradient;
std::queue<std::string> file_queue;
std::mutex gradient_mutex;
std::mutex files_mutex;
std::condition_variable file_cv;
std::atomic<bool> done_training(false);

struct node {
  std::string ip,
  int port
};

class coordinatorHandler : virtual public coordinatorIf {
 public:
  int scheduling_policy;
  coordinatorHandler(int policy) {
    // Your initialization goes here
    this->scheduling_policy = policy;
  }

  double train(const std::string& dir, const int32_t rounds, const int32_t epochs, const int32_t h, const int32_t k, const double eta) {
    // Your implementation goes here
    printf("train\n");
    mlp almighty;
    // populate training file names
    {
      std::lock_guard<std::mutex> lock(files_mutex);
      file_queue = findTrainingFiles(dir);
    }
    // init almighty
    almighty.init_training_random(file_queue.front(), k, h);
    // clear out before readding during training
    {
      std::lock_guard<std::mutex> lock(files_mutex);
      while (!file_queue.empty()) file_queue.pop();
    }
    // initialize shared gradient
    gradient_mutex.lock();
    almighty.get_weights(shared_gradient.v, shared_gradient.w);
    gradient_mutex.unlock();

    // acquire online nodes
    std::vector<node> online_nodes = gather_online_nodes(extract_nodes_info("../compute_nodes.txt"));
    // spawn threads for each online node to work through training files
    vector<std::thread> threads;
    for (const auto& n : online_nodes) {
      threads.push_back(std::thread(&coordinatorHandler::thread_func, this, n, std::ref(almighty), eta, epochs));
    }
    // for loop to start rounds
    for (int i=0; i < rounds; i++) {
      // initialize (zero out) shared gradient
      {
        std::lock_guard<std::mutex> lock(gradient_mutex);
        scale_matricies(shared_gradient.v, 0);
        scale_matricies(shared_gradient.w, 0);
      }

      // populate queue of training files then notify threads
      {
        std::lock_guard<std::mutex> lock(files_mutex);
        file_queue = findTrainingFiles(dir);
      }
      file_cv.notify_all();
      

      // divide gradient by total training files

      // update weights of almighty

      // print validate error on current round

    }
    // join threads
    for (auto& t : threads) {
      if (t.joinable()) {
        t.join();
      }
    }
    done_training.store(true);
    file_cv.notify_all();
    // return validation error
    
  }

  // thread execution
  void thread_func(node n, mlp& model, double eta, int32_t epochs) {
    std::string training_file;
    while (true) {
      {
        std::unique_lock<std::mutex> lock(files_mutex);
        file_cv.wait(lock, [&] {
          return !file_queue.empty() || done_training.load();
        });

        if (done_training.load() && file_queue.empty()) {
          break;
        }

        training_file = file_queue.front();
        file_queue.pop();
        

      }
      // actually contact a node
      
    }
  }

  // extract nodes from compute_nodes.txt
  std::vector<node> extract_nodes_info(const std::string& filename) {
    std::vector<node> nodes;
    std::ifstream file(filename);

    if (!file.is_open()) {
        std::cerr << "Error opening file: " << filename << std::endl;
        return nodes;
    }

    std::string line;
    while (std::getline(file, line)) {
        std::stringstream ss(line);
        node n;
        std::getline(ss, n.ip, ',');
        ss >> n.port;
        nodes.push_back(n);
    }

    file.close();
    return nodes;
  }

  // return true if node online, false if not
  bool test_online_node(std::string ip, int port) {
    std::shared_ptr<TTransport> socket(new TSocket(ip, port));
    std::shared_ptr<TTransport> transport(new TBufferedTransport(socket));
    std::shared_ptr<TProtocol> protocol(new TBinaryProtocol(transport));
    ComputeClient client(protocol);
  
    try {
      transport->open();
      client.check_availability()
      transport->close();
      return true;
    } 
    catch (TException& tx) {
      return false;
    }
  }

  // return online nodes from all_nodes
  std::vector<node> gather_online_nodes(std::vector<node> all_nodes) {
    std::vector<node> online_nodes;
    for (const auto& n : all_nodes) {
        if (test_online_node(n.ip, n.port)) {
            online_nodes.push_back(n);
        }
    }
    return online_nodes;
  }

  // populate training file queue
  std::queue<std::string> findTrainingFiles(const std::string& directory) {
    std::queue<std::string> matchingFiles;
    fs::path basePath = fs::absolute(directory);

    for (const auto& entry : fs::directory_iterator(basePath)) {
        if (entry.is_regular_file()) {
            std::string fullPath = entry.path().string();
            if (fullPath.find("train") != std::string::npos) {
                matchingFiles.push(fullPath);
            }
        }
    }
    return matchingFiles;
  }

};

int main(int argc, char **argv) {
  if (argc < 3) {
    std::cout << "Usage: ./coordinator <port> <scheduling_policy>" << std::endl;
    return 1;
  }
    
  int port = std::stoi(argv[1]);
  int scheduling_policy = std::stoi(argv[2]);
    
  if (scheduling_policy != 1 && scheduling_policy != 2) {
    std::cerr << "Invalid scheduling policy. Use 1 for random or 2 for load-balancing." << std::endl;
    return 1;
  }

  ::std::shared_ptr<coordinatorHandler> handler(new coordinatorHandler(scheduling_policy));
  ::std::shared_ptr<TProcessor> processor(new coordinatorProcessor(handler));
  ::std::shared_ptr<TServerTransport> serverTransport(new TServerSocket(port));
  ::std::shared_ptr<TTransportFactory> transportFactory(new TBufferedTransportFactory());
  ::std::shared_ptr<TProtocolFactory> protocolFactory(new TBinaryProtocolFactory());

  TSimpleServer server(processor, serverTransport, transportFactory, protocolFactory);
  server.serve();
  return 0;
}

